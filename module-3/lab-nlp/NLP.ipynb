{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this\n",
    "this\n",
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'this' from '/Users/anielkaaslan/anaconda3/lib/python3.7/this.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen = this\n",
    "zen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gur Mra bs Clguba, ol Gvz Crgref\\n\\nOrnhgvshy vf orggre guna htyl.\\nRkcyvpvg vf orggre guna vzcyvpvg.\\nFvzcyr vf orggre guna pbzcyrk.\\nPbzcyrk vf orggre guna pbzcyvpngrq.\\nSyng vf orggre guna arfgrq.\\nFcnefr vf orggre guna qrafr.\\nErnqnovyvgl pbhagf.\\nFcrpvny pnfrf nera'g fcrpvny rabhtu gb oernx gur ehyrf.\\nNygubhtu cenpgvpnyvgl orngf chevgl.\\nReebef fubhyq arire cnff fvyragyl.\\nHayrff rkcyvpvgyl fvyraprq.\\nVa gur snpr bs nzovthvgl, ershfr gur grzcgngvba gb thrff.\\nGurer fubhyq or bar-- naq cersrenoyl bayl bar --boivbhf jnl gb qb vg.\\nNygubhtu gung jnl znl abg or boivbhf ng svefg hayrff lbh'er Qhgpu.\\nAbj vf orggre guna arire.\\nNygubhtu arire vf bsgra orggre guna *evtug* abj.\\nVs gur vzcyrzragngvba vf uneq gb rkcynva, vg'f n onq vqrn.\\nVs gur vzcyrzragngvba vf rnfl gb rkcynva, vg znl or n tbbq vqrn.\\nAnzrfcnprf ner bar ubaxvat terng vqrn -- yrg'f qb zber bs gubfr!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren't special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you're Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it's a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let's do more of those!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codecs import decode\n",
    "\n",
    "raw_text = decode(this.s, 'rot-13')\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The Zen of Python, by Tim Peters\n",
       "\n",
       "Beautiful is better than ugly.\n",
       "Explicit is better than implicit.\n",
       "Simple is better than complex.\n",
       "Complex is better than complicated.\n",
       "Flat is better than nested.\n",
       "Sparse is better than dense.\n",
       "Readability counts.\n",
       "Special cases aren't special enough to break the rules.\n",
       "Although practicality beats purity.\n",
       "Errors should never pass silently.\n",
       "Unless explicitly silenced.\n",
       "In the face of ambiguity, refuse the temptation to guess.\n",
       "There should be one-- and preferably only one --obvious way to do it.\n",
       "Although that way may not be obvious at first unless you're Dutch.\n",
       "Now is better than never.\n",
       "Although never is often better than *right* now.\n",
       "If the implementation is hard to explain, it's a bad idea.\n",
       "If the implementation is easy to explain, it may be a good idea.\n",
       "Namespaces are one honking great idea -- let's do more of those!\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String operations and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beautiful is better than ugly.\n",
       "Explicit is better than implicit.\n",
       "Simple is better than complex.\n",
       "Complex is better than complicated.\n",
       "Flat is better than nested.\n",
       "Sparse is better than dense.\n",
       "Readability counts.\n",
       "Special cases aren't special enough to break the rules.\n",
       "Although practicality beats purity.\n",
       "Errors should never pass silently.\n",
       "Unless explicitly silenced.\n",
       "In the face of ambiguity, refuse the temptation to guess.\n",
       "There should be one-- and preferably only one --obvious way to do it.\n",
       "Although that way may not be obvious at first unless you're Dutch.\n",
       "Now is better than never.\n",
       "Although never is often better than *right* now.\n",
       "If the implementation is hard to explain, it's a bad idea.\n",
       "If the implementation is easy to explain, it may be a good idea.\n",
       "Namespaces are one honking great idea -- let's do more of those!\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen = TextBlob(raw_text)[34:]\n",
    "zen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen[:30].upper() == \"BEAUTIFUL IS BETTER THAN UGLY.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anielkaaslan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Beautiful is better than ugly.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\"),\n",
       " Sentence(\"Complex is better than complicated.\"),\n",
       " Sentence(\"Flat is better than nested.\"),\n",
       " Sentence(\"Sparse is better than dense.\"),\n",
       " Sentence(\"Readability counts.\"),\n",
       " Sentence(\"Special cases aren't special enough to break the rules.\"),\n",
       " Sentence(\"Although practicality beats purity.\"),\n",
       " Sentence(\"Errors should never pass silently.\"),\n",
       " Sentence(\"Unless explicitly silenced.\"),\n",
       " Sentence(\"In the face of ambiguity, refuse the temptation to guess.\"),\n",
       " Sentence(\"There should be one-- and preferably only one --obvious way to do it.\"),\n",
       " Sentence(\"Although that way may not be obvious at first unless you're Dutch.\"),\n",
       " Sentence(\"Now is better than never.\"),\n",
       " Sentence(\"Although never is often better than *right* now.\"),\n",
       " Sentence(\"If the implementation is hard to explain, it's a bad idea.\"),\n",
       " Sentence(\"If the implementation is easy to explain, it may be a good idea.\"),\n",
       " Sentence(\"Namespaces are one honking great idea -- let's do more of those!\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "# punkt\n",
    "nltk.download('punkt')\n",
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex', 'Complex', 'is', 'better', 'than', 'complicated', 'Flat', 'is', 'better', 'than', 'nested', 'Sparse', 'is', 'better', 'than', 'dense', 'Readability', 'counts', 'Special', 'cases', 'are', \"n't\", 'special', 'enough', 'to', 'break', 'the', 'rules', 'Although', 'practicality', 'beats', 'purity', 'Errors', 'should', 'never', 'pass', 'silently', 'Unless', 'explicitly', 'silenced', 'In', 'the', 'face', 'of', 'ambiguity', 'refuse', 'the', 'temptation', 'to', 'guess', 'There', 'should', 'be', 'one', 'and', 'preferably', 'only', 'one', 'obvious', 'way', 'to', 'do', 'it', 'Although', 'that', 'way', 'may', 'not', 'be', 'obvious', 'at', 'first', 'unless', 'you', \"'re\", 'Dutch', 'Now', 'is', 'better', 'than', 'never', 'Although', 'never', 'is', 'often', 'better', 'than', 'right', 'now', 'If', 'the', 'implementation', 'is', 'hard', 'to', 'explain', 'it', \"'s\", 'a', 'bad', 'idea', 'If', 'the', 'implementation', 'is', 'easy', 'to', 'explain', 'it', 'may', 'be', 'a', 'good', 'idea', 'Namespaces', 'are', 'one', 'honking', 'great', 'idea', 'let', \"'s\", 'do', 'more', 'of', 'those'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordlist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A WordList is a list with additional methods\n",
    "\n",
    "Reference: https://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.WordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.words.count('is', case_sensitive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"Beautiful is better than ugly.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautifuls', 'iss', 'betters', 'thans', 'uglies'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences[0].words.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech (POS) tagging\n",
    "\n",
    "| Tag | Description |\n",
    "| --- | --- |\n",
    "| IN | Preposition or coordinting conjunction |\n",
    "| JJR | Adjective, comparative |\n",
    "| NNP | Proper noun, singular |\n",
    "| RB | Adverb |\n",
    "| VBZ | Verb, 3rd person singular present|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/anielkaaslan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Beautiful', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('ugly', 'RB')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "zen.sentences[0].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/anielkaaslan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['beautiful', 'explicit', 'simple', 'complex', 'flat', 'sparse', 'readability', 'special cases', 'practicality beats purity', 'errors', 'unless', 'obvious way', 'dutch', 'bad idea', 'good idea', 'namespaces', 'great idea'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "zen.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "* Polarity measures attitude as float between -1 (negative sentiment) and 1 (positive sentiment)\n",
    "* Subjectivity measures facts vs. opinions as a float between 0 (very objective) and 1 (very subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.2166666666666667, subjectivity=0.8333333333333334)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beautiful is better than uggly\n",
    "zen.sentences[0].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Five is greater than four\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "* Reduces a word to its roots form (\"stem\") even if the stem itself is not a valid word\n",
    "* By default, uses \"Porter\" stemming library from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'climb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('climbing').stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful: beauti\n",
      "ugly: ugli\n",
      "Explicit: explicit\n",
      "Simple: simpl\n",
      "Complex: complex\n",
      "complicated: complic\n",
      "Flat: flat\n",
      "nested: nest\n",
      "Sparse: spars\n",
      "dense: dens\n",
      "Readability: readabl\n",
      "counts: count\n",
      "Special: special\n",
      "cases: case\n",
      "rules: rule\n",
      "Although: although\n",
      "practicality: practic\n",
      "beats: beat\n",
      "purity: puriti\n",
      "Errors: error\n",
      "silently: silent\n",
      "Unless: unless\n",
      "explicitly: explicitli\n",
      "silenced: silenc\n",
      "ambiguity: ambigu\n",
      "refuse: refus\n",
      "temptation: temptat\n",
      "There: there\n",
      "preferably: prefer\n",
      "only: onli\n",
      "obvious: obviou\n",
      "Although: although\n",
      "obvious: obviou\n",
      "Dutch: dutch\n",
      "Now: now\n",
      "Although: although\n",
      "implementation: implement\n",
      "implementation: implement\n",
      "easy: easi\n",
      "Namespaces: namespac\n",
      "honking: honk\n"
     ]
    }
   ],
   "source": [
    "for w in zen.words:\n",
    "    stem = Word(w).stem()\n",
    "    if w != stem:\n",
    "        print(f\"{w}: {stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "* Reduces a word to its stem word in the target language\n",
    "* Considers context (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: count\n",
      "cases: case\n",
      "rules: rule\n",
      "beats: beat\n",
      "pass: pas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anielkaaslan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "for w in zen.words:\n",
    "    stem = Word(w).lemmatize()\n",
    "    if w != stem:\n",
    "        print(f\"{w}: {stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'beautiful': 1,\n",
       "             'is': 10,\n",
       "             'better': 8,\n",
       "             'than': 8,\n",
       "             'ugly': 1,\n",
       "             'explicit': 1,\n",
       "             'implicit': 1,\n",
       "             'simple': 1,\n",
       "             'complex': 2,\n",
       "             'complicated': 1,\n",
       "             'flat': 1,\n",
       "             'nested': 1,\n",
       "             'sparse': 1,\n",
       "             'dense': 1,\n",
       "             'readability': 1,\n",
       "             'counts': 1,\n",
       "             'special': 2,\n",
       "             'cases': 1,\n",
       "             'are': 2,\n",
       "             \"n't\": 1,\n",
       "             'enough': 1,\n",
       "             'to': 5,\n",
       "             'break': 1,\n",
       "             'the': 5,\n",
       "             'rules': 1,\n",
       "             'although': 3,\n",
       "             'practicality': 1,\n",
       "             'beats': 1,\n",
       "             'purity': 1,\n",
       "             'errors': 1,\n",
       "             'should': 2,\n",
       "             'never': 3,\n",
       "             'pass': 1,\n",
       "             'silently': 1,\n",
       "             'unless': 2,\n",
       "             'explicitly': 1,\n",
       "             'silenced': 1,\n",
       "             'in': 1,\n",
       "             'face': 1,\n",
       "             'of': 2,\n",
       "             'ambiguity': 1,\n",
       "             'refuse': 1,\n",
       "             'temptation': 1,\n",
       "             'guess': 1,\n",
       "             'there': 1,\n",
       "             'be': 3,\n",
       "             'one': 3,\n",
       "             'and': 1,\n",
       "             'preferably': 1,\n",
       "             'only': 1,\n",
       "             'obvious': 2,\n",
       "             'way': 2,\n",
       "             'do': 2,\n",
       "             'it': 3,\n",
       "             'that': 1,\n",
       "             'may': 2,\n",
       "             'not': 1,\n",
       "             'at': 1,\n",
       "             'first': 1,\n",
       "             'you': 1,\n",
       "             're': 1,\n",
       "             'dutch': 1,\n",
       "             'now': 2,\n",
       "             'often': 1,\n",
       "             'right': 1,\n",
       "             'if': 2,\n",
       "             'implementation': 2,\n",
       "             'hard': 1,\n",
       "             'explain': 2,\n",
       "             's': 2,\n",
       "             'a': 2,\n",
       "             'bad': 1,\n",
       "             'idea': 3,\n",
       "             'easy': 1,\n",
       "             'good': 1,\n",
       "             'namespaces': 1,\n",
       "             'honking': 1,\n",
       "             'great': 1,\n",
       "             'let': 1,\n",
       "             'more': 1,\n",
       "             'those': 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'beautiful': 1,\n",
       "             'explicit': 1,\n",
       "             'simple': 1,\n",
       "             'complex': 1,\n",
       "             'flat': 1,\n",
       "             'sparse': 1,\n",
       "             'readability': 1,\n",
       "             'special cases': 1,\n",
       "             'practicality beats purity': 1,\n",
       "             'errors': 1,\n",
       "             'unless': 1,\n",
       "             'obvious way': 1,\n",
       "             'dutch': 1,\n",
       "             'bad idea': 1,\n",
       "             'good idea': 1,\n",
       "             'namespaces': 1,\n",
       "             'great idea': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.np_counts # Noun phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Beautiful', 'is']),\n",
       " WordList(['is', 'better']),\n",
       " WordList(['better', 'than']),\n",
       " WordList(['than', 'ugly'])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences[0].ngrams(n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Beautiful', 'is', 'better', 'than']),\n",
       " WordList(['is', 'better', 'than', 'ugly'])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences[0].ngrams(n = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I can spell good\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"I cann spel goood\").correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "* Uses Google Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"Hermoso es mejor que feo.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences[0].translate(to = 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"love\")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('amor').translate(to = 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "TextBlob doesn't have a built-in stopwords removal method, so we have to use NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anielkaaslan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "#len(en_stopwords)\n",
    "en_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this sandwich.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an amazing place!</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I feel very good about these beers.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is my best work.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What an awesome view</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence sentiment\n",
       "0                I love this sandwich.       pos\n",
       "1            This is an amazing place!       pos\n",
       "2  I feel very good about these beers.       pos\n",
       "3                This is my best work.       pos\n",
       "4                 What an awesome view       pos"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.DataFrame(\n",
    "    data = [('I love this sandwich.', 'pos'),\n",
    "        ('This is an amazing place!', 'pos'),\n",
    "        ('I feel very good about these beers.', 'pos'),\n",
    "        ('This is my best work.', 'pos'),\n",
    "        (\"What an awesome view\", 'pos'),\n",
    "        ('I do not like this restaurant', 'neg'),\n",
    "        ('I am tired of this stuff.', 'neg'),\n",
    "        (\"I can't deal with this\", 'neg'),\n",
    "        ('He is my sworn enemy!', 'neg'),\n",
    "        ('My boss is horrible.', 'neg')],\n",
    "    columns = ['sentence', 'sentiment']\n",
    ")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I love this sandwich.', 'pos'],\n",
       "       ['This is an amazing place!', 'pos'],\n",
       "       ['I feel very good about these beers.', 'pos'],\n",
       "       ['This is my best work.', 'pos'],\n",
       "       ['What an awesome view', 'pos'],\n",
       "       ['I do not like this restaurant', 'neg'],\n",
       "       ['I am tired of this stuff.', 'neg'],\n",
       "       [\"I can't deal with this\", 'neg'],\n",
       "       ['He is my sworn enemy!', 'neg'],\n",
       "       ['My boss is horrible.', 'neg']], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "model = NaiveBayesClassifier(train.values)\n",
    "model.classify(\"The beer was horrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(\n",
    "    data = [\n",
    "        ('The beer was good.', 'pos'),\n",
    "        ('I do not enjoy my job', 'neg'),\n",
    "        (\"I ain't feeling dandy today.\", 'neg'),\n",
    "        (\"I feel amazing!\", 'pos'),\n",
    "        ('Gary is a friend of mine.', 'pos'),\n",
    "        (\"I can't believe I'm doing this.\", 'neg')\n",
    "    ],\n",
    "    columns = ['sentence', 'sentiment']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "model.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF - IDF with SciKit Learn\n",
    "Term frequency / Inverse document frequency\n",
    "\n",
    "Vocabulary:\n",
    "- A vector is a tuple of one or more values\n",
    "- vector values are called scalars\n",
    "- a sparse matrix contains mostly null values\n",
    "- a dense matrix contains mostly non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love this sandwich.', 'This is an amazing place!',\n",
       "       'I feel very good about these beers.', 'This is my best work.',\n",
       "       'What an awesome view', 'I do not like this restaurant',\n",
       "       'I am tired of this stuff.', \"I can't deal with this\",\n",
       "       'He is my sworn enemy!', 'My boss is horrible.'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "word_count_vectors = tfidf.fit_transform(\n",
    "    train['sentence'].apply(\n",
    "        lambda x: ' '.join([w for w in x.lower().split() if w not in en_stopwords])\n",
    "    ).values\n",
    ").todense().tolist()\n",
    "\n",
    "word_count_vectors[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>awesome</th>\n",
       "      <th>beers</th>\n",
       "      <th>best</th>\n",
       "      <th>boss</th>\n",
       "      <th>can</th>\n",
       "      <th>deal</th>\n",
       "      <th>enemy</th>\n",
       "      <th>feel</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>place</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>sandwich</th>\n",
       "      <th>stuff</th>\n",
       "      <th>sworn</th>\n",
       "      <th>tired</th>\n",
       "      <th>view</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing   awesome    beers      best      boss       can      deal  \\\n",
       "0  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.707107  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.57735  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.00000  0.707107  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.707107  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.00000  0.000000  0.000000  0.707107  0.707107   \n",
       "8  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000  0.00000  0.000000  0.707107  0.000000  0.000000   \n",
       "\n",
       "      enemy     feel     good  ...      like      love     place  restaurant  \\\n",
       "0  0.000000  0.00000  0.00000  ...  0.000000  0.707107  0.000000    0.000000   \n",
       "1  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.707107    0.000000   \n",
       "2  0.000000  0.57735  0.57735  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "3  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "4  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "5  0.000000  0.00000  0.00000  ...  0.707107  0.000000  0.000000    0.707107   \n",
       "6  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "7  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "8  0.707107  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "9  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000    0.000000   \n",
       "\n",
       "   sandwich     stuff     sworn     tired      view      work  \n",
       "0  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.707107  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6  0.000000  0.707107  0.000000  0.707107  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8  0.000000  0.000000  0.707107  0.000000  0.000000  0.000000  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    data = word_count_vectors,\n",
    "    columns = tfidf.get_feature_names() #calculate the term freq of each \n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work          0.707107\n",
       "like          0.707107\n",
       "awesome       0.707107\n",
       "best          0.707107\n",
       "boss          0.707107\n",
       "can           0.707107\n",
       "deal          0.707107\n",
       "enemy         0.707107\n",
       "view          0.707107\n",
       "horrible      0.707107\n",
       "love          0.707107\n",
       "place         0.707107\n",
       "restaurant    0.707107\n",
       "sandwich      0.707107\n",
       "stuff         0.707107\n",
       "sworn         0.707107\n",
       "tired         0.707107\n",
       "amazing       0.707107\n",
       "good          0.577350\n",
       "feel          0.577350\n",
       "beers         0.577350\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
